{"format": "torch", "nodes": [{"name": "electra", "id": 139919044905616, "class_name": "ElectraModel(\n  (embeddings): ElectraEmbeddings(\n    (word_embeddings): Embedding(35000, 128, padding_idx=0)\n    (position_embeddings): Embedding(512, 128)\n    (token_type_embeddings): Embedding(2, 128)\n    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n  (encoder): ElectraEncoder(\n    (layer): ModuleList(\n      (0): ElectraLayer(\n        (attention): ElectraAttention(\n          (self): ElectraSelfAttention(\n            (query): Linear(in_features=256, out_features=256, bias=True)\n            (key): Linear(in_features=256, out_features=256, bias=True)\n            (value): Linear(in_features=256, out_features=256, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): ElectraSelfOutput(\n            (dense): Linear(in_features=256, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): ElectraIntermediate(\n          (dense): Linear(in_features=256, out_features=1024, bias=True)\n        )\n        (output): ElectraOutput(\n          (dense): Linear(in_features=1024, out_features=256, bias=True)\n          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): ElectraLayer(\n        (attention): ElectraAttention(\n          (self): ElectraSelfAttention(\n            (query): Linear(in_features=256, out_features=256, bias=True)\n            (key): Linear(in_features=256, out_features=256, bias=True)\n            (value): Linear(in_features=256, out_features=256, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): ElectraSelfOutput(\n            (dense): Linear(in_features=256, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): ElectraIntermediate(\n          (dense): Linear(in_features=256, out_features=1024, bias=True)\n        )\n        (output): ElectraOutput(\n          (dense): Linear(in_features=1024, out_features=256, bias=True)\n          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): ElectraLayer(\n        (attention): ElectraAttention(\n          (self): ElectraSelfAttention(\n            (query): Linear(in_features=256, out_features=256, bias=True)\n            (key): Linear(in_features=256, out_features=256, bias=True)\n            (value): Linear(in_features=256, out_features=256, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): ElectraSelfOutput(\n            (dense): Linear(in_features=256, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): ElectraIntermediate(\n          (dense): Linear(in_features=256, out_features=1024, bias=True)\n        )\n        (output): ElectraOutput(\n          (dense): Linear(in_features=1024, out_features=256, bias=True)\n          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): ElectraLayer(\n        (attention): ElectraAttention(\n          (self): ElectraSelfAttention(\n            (query): Linear(in_features=256, out_features=256, bias=True)\n            (key): Linear(in_features=256, out_features=256, bias=True)\n            (value): Linear(in_features=256, out_features=256, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): ElectraSelfOutput(\n            (dense): Linear(in_features=256, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): ElectraIntermediate(\n          (dense): Linear(in_features=256, out_features=1024, bias=True)\n        )\n        (output): ElectraOutput(\n          (dense): Linear(in_features=1024, out_features=256, bias=True)\n          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): ElectraLayer(\n        (attention): ElectraAttention(\n          (self): ElectraSelfAttention(\n            (query): Linear(in_features=256, out_features=256, bias=True)\n            (key): Linear(in_features=256, out_features=256, bias=True)\n            (value): Linear(in_features=256, out_features=256, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): ElectraSelfOutput(\n            (dense): Linear(in_features=256, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): ElectraIntermediate(\n          (dense): Linear(in_features=256, out_features=1024, bias=True)\n        )\n        (output): ElectraOutput(\n          (dense): Linear(in_features=1024, out_features=256, bias=True)\n          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): ElectraLayer(\n        (attention): ElectraAttention(\n          (self): ElectraSelfAttention(\n            (query): Linear(in_features=256, out_features=256, bias=True)\n            (key): Linear(in_features=256, out_features=256, bias=True)\n            (value): Linear(in_features=256, out_features=256, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): ElectraSelfOutput(\n            (dense): Linear(in_features=256, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): ElectraIntermediate(\n          (dense): Linear(in_features=256, out_features=1024, bias=True)\n        )\n        (output): ElectraOutput(\n          (dense): Linear(in_features=1024, out_features=256, bias=True)\n          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): ElectraLayer(\n        (attention): ElectraAttention(\n          (self): ElectraSelfAttention(\n            (query): Linear(in_features=256, out_features=256, bias=True)\n            (key): Linear(in_features=256, out_features=256, bias=True)\n            (value): Linear(in_features=256, out_features=256, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): ElectraSelfOutput(\n            (dense): Linear(in_features=256, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): ElectraIntermediate(\n          (dense): Linear(in_features=256, out_features=1024, bias=True)\n        )\n        (output): ElectraOutput(\n          (dense): Linear(in_features=1024, out_features=256, bias=True)\n          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): ElectraLayer(\n        (attention): ElectraAttention(\n          (self): ElectraSelfAttention(\n            (query): Linear(in_features=256, out_features=256, bias=True)\n            (key): Linear(in_features=256, out_features=256, bias=True)\n            (value): Linear(in_features=256, out_features=256, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): ElectraSelfOutput(\n            (dense): Linear(in_features=256, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): ElectraIntermediate(\n          (dense): Linear(in_features=256, out_features=1024, bias=True)\n        )\n        (output): ElectraOutput(\n          (dense): Linear(in_features=1024, out_features=256, bias=True)\n          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): ElectraLayer(\n        (attention): ElectraAttention(\n          (self): ElectraSelfAttention(\n            (query): Linear(in_features=256, out_features=256, bias=True)\n            (key): Linear(in_features=256, out_features=256, bias=True)\n            (value): Linear(in_features=256, out_features=256, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): ElectraSelfOutput(\n            (dense): Linear(in_features=256, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): ElectraIntermediate(\n          (dense): Linear(in_features=256, out_features=1024, bias=True)\n        )\n        (output): ElectraOutput(\n          (dense): Linear(in_features=1024, out_features=256, bias=True)\n          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): ElectraLayer(\n        (attention): ElectraAttention(\n          (self): ElectraSelfAttention(\n            (query): Linear(in_features=256, out_features=256, bias=True)\n            (key): Linear(in_features=256, out_features=256, bias=True)\n            (value): Linear(in_features=256, out_features=256, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): ElectraSelfOutput(\n            (dense): Linear(in_features=256, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): ElectraIntermediate(\n          (dense): Linear(in_features=256, out_features=1024, bias=True)\n        )\n        (output): ElectraOutput(\n          (dense): Linear(in_features=1024, out_features=256, bias=True)\n          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): ElectraLayer(\n        (attention): ElectraAttention(\n          (self): ElectraSelfAttention(\n            (query): Linear(in_features=256, out_features=256, bias=True)\n            (key): Linear(in_features=256, out_features=256, bias=True)\n            (value): Linear(in_features=256, out_features=256, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): ElectraSelfOutput(\n            (dense): Linear(in_features=256, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): ElectraIntermediate(\n          (dense): Linear(in_features=256, out_features=1024, bias=True)\n        )\n        (output): ElectraOutput(\n          (dense): Linear(in_features=1024, out_features=256, bias=True)\n          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): ElectraLayer(\n        (attention): ElectraAttention(\n          (self): ElectraSelfAttention(\n            (query): Linear(in_features=256, out_features=256, bias=True)\n            (key): Linear(in_features=256, out_features=256, bias=True)\n            (value): Linear(in_features=256, out_features=256, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): ElectraSelfOutput(\n            (dense): Linear(in_features=256, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): ElectraIntermediate(\n          (dense): Linear(in_features=256, out_features=1024, bias=True)\n        )\n        (output): ElectraOutput(\n          (dense): Linear(in_features=1024, out_features=256, bias=True)\n          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n)", "parameters": [["embeddings.word_embeddings.weight", [35000, 128]], ["embeddings.position_embeddings.weight", [512, 128]], ["embeddings.token_type_embeddings.weight", [2, 128]], ["embeddings.LayerNorm.weight", [128]], ["embeddings.LayerNorm.bias", [128]], ["embeddings_project.weight", [256, 128]], ["embeddings_project.bias", [256]], ["encoder.layer.0.attention.self.query.weight", [256, 256]], ["encoder.layer.0.attention.self.query.bias", [256]], ["encoder.layer.0.attention.self.key.weight", [256, 256]], ["encoder.layer.0.attention.self.key.bias", [256]], ["encoder.layer.0.attention.self.value.weight", [256, 256]], ["encoder.layer.0.attention.self.value.bias", [256]], ["encoder.layer.0.attention.output.dense.weight", [256, 256]], ["encoder.layer.0.attention.output.dense.bias", [256]], ["encoder.layer.0.attention.output.LayerNorm.weight", [256]], ["encoder.layer.0.attention.output.LayerNorm.bias", [256]], ["encoder.layer.0.intermediate.dense.weight", [1024, 256]], ["encoder.layer.0.intermediate.dense.bias", [1024]], ["encoder.layer.0.output.dense.weight", [256, 1024]], ["encoder.layer.0.output.dense.bias", [256]], ["encoder.layer.0.output.LayerNorm.weight", [256]], ["encoder.layer.0.output.LayerNorm.bias", [256]], ["encoder.layer.1.attention.self.query.weight", [256, 256]], ["encoder.layer.1.attention.self.query.bias", [256]], ["encoder.layer.1.attention.self.key.weight", [256, 256]], ["encoder.layer.1.attention.self.key.bias", [256]], ["encoder.layer.1.attention.self.value.weight", [256, 256]], ["encoder.layer.1.attention.self.value.bias", [256]], ["encoder.layer.1.attention.output.dense.weight", [256, 256]], ["encoder.layer.1.attention.output.dense.bias", [256]], ["encoder.layer.1.attention.output.LayerNorm.weight", [256]], ["encoder.layer.1.attention.output.LayerNorm.bias", [256]], ["encoder.layer.1.intermediate.dense.weight", [1024, 256]], ["encoder.layer.1.intermediate.dense.bias", [1024]], ["encoder.layer.1.output.dense.weight", [256, 1024]], ["encoder.layer.1.output.dense.bias", [256]], ["encoder.layer.1.output.LayerNorm.weight", [256]], ["encoder.layer.1.output.LayerNorm.bias", [256]], ["encoder.layer.2.attention.self.query.weight", [256, 256]], ["encoder.layer.2.attention.self.query.bias", [256]], ["encoder.layer.2.attention.self.key.weight", [256, 256]], ["encoder.layer.2.attention.self.key.bias", [256]], ["encoder.layer.2.attention.self.value.weight", [256, 256]], ["encoder.layer.2.attention.self.value.bias", [256]], ["encoder.layer.2.attention.output.dense.weight", [256, 256]], ["encoder.layer.2.attention.output.dense.bias", [256]], ["encoder.layer.2.attention.output.LayerNorm.weight", [256]], ["encoder.layer.2.attention.output.LayerNorm.bias", [256]], ["encoder.layer.2.intermediate.dense.weight", [1024, 256]], ["encoder.layer.2.intermediate.dense.bias", [1024]], ["encoder.layer.2.output.dense.weight", [256, 1024]], ["encoder.layer.2.output.dense.bias", [256]], ["encoder.layer.2.output.LayerNorm.weight", [256]], ["encoder.layer.2.output.LayerNorm.bias", [256]], ["encoder.layer.3.attention.self.query.weight", [256, 256]], ["encoder.layer.3.attention.self.query.bias", [256]], ["encoder.layer.3.attention.self.key.weight", [256, 256]], ["encoder.layer.3.attention.self.key.bias", [256]], ["encoder.layer.3.attention.self.value.weight", [256, 256]], ["encoder.layer.3.attention.self.value.bias", [256]], ["encoder.layer.3.attention.output.dense.weight", [256, 256]], ["encoder.layer.3.attention.output.dense.bias", [256]], ["encoder.layer.3.attention.output.LayerNorm.weight", [256]], ["encoder.layer.3.attention.output.LayerNorm.bias", [256]], ["encoder.layer.3.intermediate.dense.weight", [1024, 256]], ["encoder.layer.3.intermediate.dense.bias", [1024]], ["encoder.layer.3.output.dense.weight", [256, 1024]], ["encoder.layer.3.output.dense.bias", [256]], ["encoder.layer.3.output.LayerNorm.weight", [256]], ["encoder.layer.3.output.LayerNorm.bias", [256]], ["encoder.layer.4.attention.self.query.weight", [256, 256]], ["encoder.layer.4.attention.self.query.bias", [256]], ["encoder.layer.4.attention.self.key.weight", [256, 256]], ["encoder.layer.4.attention.self.key.bias", [256]], ["encoder.layer.4.attention.self.value.weight", [256, 256]], ["encoder.layer.4.attention.self.value.bias", [256]], ["encoder.layer.4.attention.output.dense.weight", [256, 256]], ["encoder.layer.4.attention.output.dense.bias", [256]], ["encoder.layer.4.attention.output.LayerNorm.weight", [256]], ["encoder.layer.4.attention.output.LayerNorm.bias", [256]], ["encoder.layer.4.intermediate.dense.weight", [1024, 256]], ["encoder.layer.4.intermediate.dense.bias", [1024]], ["encoder.layer.4.output.dense.weight", [256, 1024]], ["encoder.layer.4.output.dense.bias", [256]], ["encoder.layer.4.output.LayerNorm.weight", [256]], ["encoder.layer.4.output.LayerNorm.bias", [256]], ["encoder.layer.5.attention.self.query.weight", [256, 256]], ["encoder.layer.5.attention.self.query.bias", [256]], ["encoder.layer.5.attention.self.key.weight", [256, 256]], ["encoder.layer.5.attention.self.key.bias", [256]], ["encoder.layer.5.attention.self.value.weight", [256, 256]], ["encoder.layer.5.attention.self.value.bias", [256]], ["encoder.layer.5.attention.output.dense.weight", [256, 256]], ["encoder.layer.5.attention.output.dense.bias", [256]], ["encoder.layer.5.attention.output.LayerNorm.weight", [256]], ["encoder.layer.5.attention.output.LayerNorm.bias", [256]], ["encoder.layer.5.intermediate.dense.weight", [1024, 256]], ["encoder.layer.5.intermediate.dense.bias", [1024]], ["encoder.layer.5.output.dense.weight", [256, 1024]], ["encoder.layer.5.output.dense.bias", [256]], ["encoder.layer.5.output.LayerNorm.weight", [256]], ["encoder.layer.5.output.LayerNorm.bias", [256]], ["encoder.layer.6.attention.self.query.weight", [256, 256]], ["encoder.layer.6.attention.self.query.bias", [256]], ["encoder.layer.6.attention.self.key.weight", [256, 256]], ["encoder.layer.6.attention.self.key.bias", [256]], ["encoder.layer.6.attention.self.value.weight", [256, 256]], ["encoder.layer.6.attention.self.value.bias", [256]], ["encoder.layer.6.attention.output.dense.weight", [256, 256]], ["encoder.layer.6.attention.output.dense.bias", [256]], ["encoder.layer.6.attention.output.LayerNorm.weight", [256]], ["encoder.layer.6.attention.output.LayerNorm.bias", [256]], ["encoder.layer.6.intermediate.dense.weight", [1024, 256]], ["encoder.layer.6.intermediate.dense.bias", [1024]], ["encoder.layer.6.output.dense.weight", [256, 1024]], ["encoder.layer.6.output.dense.bias", [256]], ["encoder.layer.6.output.LayerNorm.weight", [256]], ["encoder.layer.6.output.LayerNorm.bias", [256]], ["encoder.layer.7.attention.self.query.weight", [256, 256]], ["encoder.layer.7.attention.self.query.bias", [256]], ["encoder.layer.7.attention.self.key.weight", [256, 256]], ["encoder.layer.7.attention.self.key.bias", [256]], ["encoder.layer.7.attention.self.value.weight", [256, 256]], ["encoder.layer.7.attention.self.value.bias", [256]], ["encoder.layer.7.attention.output.dense.weight", [256, 256]], ["encoder.layer.7.attention.output.dense.bias", [256]], ["encoder.layer.7.attention.output.LayerNorm.weight", [256]], ["encoder.layer.7.attention.output.LayerNorm.bias", [256]], ["encoder.layer.7.intermediate.dense.weight", [1024, 256]], ["encoder.layer.7.intermediate.dense.bias", [1024]], ["encoder.layer.7.output.dense.weight", [256, 1024]], ["encoder.layer.7.output.dense.bias", [256]], ["encoder.layer.7.output.LayerNorm.weight", [256]], ["encoder.layer.7.output.LayerNorm.bias", [256]], ["encoder.layer.8.attention.self.query.weight", [256, 256]], ["encoder.layer.8.attention.self.query.bias", [256]], ["encoder.layer.8.attention.self.key.weight", [256, 256]], ["encoder.layer.8.attention.self.key.bias", [256]], ["encoder.layer.8.attention.self.value.weight", [256, 256]], ["encoder.layer.8.attention.self.value.bias", [256]], ["encoder.layer.8.attention.output.dense.weight", [256, 256]], ["encoder.layer.8.attention.output.dense.bias", [256]], ["encoder.layer.8.attention.output.LayerNorm.weight", [256]], ["encoder.layer.8.attention.output.LayerNorm.bias", [256]], ["encoder.layer.8.intermediate.dense.weight", [1024, 256]], ["encoder.layer.8.intermediate.dense.bias", [1024]], ["encoder.layer.8.output.dense.weight", [256, 1024]], ["encoder.layer.8.output.dense.bias", [256]], ["encoder.layer.8.output.LayerNorm.weight", [256]], ["encoder.layer.8.output.LayerNorm.bias", [256]], ["encoder.layer.9.attention.self.query.weight", [256, 256]], ["encoder.layer.9.attention.self.query.bias", [256]], ["encoder.layer.9.attention.self.key.weight", [256, 256]], ["encoder.layer.9.attention.self.key.bias", [256]], ["encoder.layer.9.attention.self.value.weight", [256, 256]], ["encoder.layer.9.attention.self.value.bias", [256]], ["encoder.layer.9.attention.output.dense.weight", [256, 256]], ["encoder.layer.9.attention.output.dense.bias", [256]], ["encoder.layer.9.attention.output.LayerNorm.weight", [256]], ["encoder.layer.9.attention.output.LayerNorm.bias", [256]], ["encoder.layer.9.intermediate.dense.weight", [1024, 256]], ["encoder.layer.9.intermediate.dense.bias", [1024]], ["encoder.layer.9.output.dense.weight", [256, 1024]], ["encoder.layer.9.output.dense.bias", [256]], ["encoder.layer.9.output.LayerNorm.weight", [256]], ["encoder.layer.9.output.LayerNorm.bias", [256]], ["encoder.layer.10.attention.self.query.weight", [256, 256]], ["encoder.layer.10.attention.self.query.bias", [256]], ["encoder.layer.10.attention.self.key.weight", [256, 256]], ["encoder.layer.10.attention.self.key.bias", [256]], ["encoder.layer.10.attention.self.value.weight", [256, 256]], ["encoder.layer.10.attention.self.value.bias", [256]], ["encoder.layer.10.attention.output.dense.weight", [256, 256]], ["encoder.layer.10.attention.output.dense.bias", [256]], ["encoder.layer.10.attention.output.LayerNorm.weight", [256]], ["encoder.layer.10.attention.output.LayerNorm.bias", [256]], ["encoder.layer.10.intermediate.dense.weight", [1024, 256]], ["encoder.layer.10.intermediate.dense.bias", [1024]], ["encoder.layer.10.output.dense.weight", [256, 1024]], ["encoder.layer.10.output.dense.bias", [256]], ["encoder.layer.10.output.LayerNorm.weight", [256]], ["encoder.layer.10.output.LayerNorm.bias", [256]], ["encoder.layer.11.attention.self.query.weight", [256, 256]], ["encoder.layer.11.attention.self.query.bias", [256]], ["encoder.layer.11.attention.self.key.weight", [256, 256]], ["encoder.layer.11.attention.self.key.bias", [256]], ["encoder.layer.11.attention.self.value.weight", [256, 256]], ["encoder.layer.11.attention.self.value.bias", [256]], ["encoder.layer.11.attention.output.dense.weight", [256, 256]], ["encoder.layer.11.attention.output.dense.bias", [256]], ["encoder.layer.11.attention.output.LayerNorm.weight", [256]], ["encoder.layer.11.attention.output.LayerNorm.bias", [256]], ["encoder.layer.11.intermediate.dense.weight", [1024, 256]], ["encoder.layer.11.intermediate.dense.bias", [1024]], ["encoder.layer.11.output.dense.weight", [256, 1024]], ["encoder.layer.11.output.dense.bias", [256]], ["encoder.layer.11.output.LayerNorm.weight", [256]], ["encoder.layer.11.output.LayerNorm.bias", [256]]], "output_shape": [[[[0], [0], [0], [0], [0], [0], [0], [0], 0, [0], [0], 0, 0, 0, 0, 0, 0]]], "num_parameters": [4480000, 65536, 256, 128, 128, 32768, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256]}, {"name": "qa_outputs", "id": 139919044912656, "class_name": "Linear(in_features=256, out_features=2, bias=True)", "parameters": [["weight", [2, 256]], ["bias", [2]]], "output_shape": [[8, 384, 2]], "num_parameters": [512, 2]}], "edges": []}